{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "white2black-cycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wKIXr0H3Ksv",
        "colab_type": "text"
      },
      "source": [
        "# Cycle GAN\n",
        "\n",
        "white2black for T-shirts Cycle GAN (weights in the repository)\n",
        "\n",
        "https://github.com/t0efL/white2black-GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c7H4DyUkYAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "import argparse\n",
        "import itertools\n",
        "\n",
        "from PIL import Image\n",
        "import glob\n",
        "from IPython.display import clear_output\n",
        "import shutil \n",
        "from tqdm import tqdm\n",
        "import PIL\n",
        "\n",
        "import fastai\n",
        "import fastai.vision\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models, datasets\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzFlLSGv9Mhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect your Google Drive.\n",
        "# You will need it for save or load weights and getting a dataset.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3wTHx4W4P76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting a dataset from your Google Drive. \n",
        "# You should have put it in the root of your disk beforehand.\n",
        "!unzip -q /content/gdrive/My\\ Drive/white2black.zip  # It takes about 3 minutes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtOZdCQ5kYA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./output'):\n",
        "    os.mkdir('./output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieRYovfcwH9",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwdV5Vj5kYA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed=27):\n",
        "    \"\"\"Sets the random seeds.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7eeKKXkYA_",
        "colab_type": "code",
        "outputId": "205f2f4f-e9d3-40fd-9681-f29c3fb9a027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Setting a device. I recommend you use Google Colab.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !nvidia-smi\n",
        "else:\n",
        "    print('Cuda is not available.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 15 13:00:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPDZD6mZkYBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None, plt_ax=None, default=False):\n",
        "    \"\"\"Image show.\"\"\"\n",
        "    if plt_ax is None:\n",
        "        plt_ax = plt.gca()\n",
        "    if title is None and type(inp) is tuple:\n",
        "        inp, title = inp\n",
        "    if type(inp) is tuple:\n",
        "        inp = inp[0]\n",
        "    if type(inp) is PIL.Image.Image:\n",
        "        inp = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])(inp)\n",
        "    if type(inp) is torch.Tensor and inp.is_cuda:\n",
        "        inp = inp.cpu()\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    \n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt_ax.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt_ax.set_title(title)\n",
        "    plt_ax.grid(False)\n",
        "    \n",
        "    \n",
        "def grid_show(data, max_images=9, random=False):\n",
        "    \"\"\"Grid show.\"\"\"\n",
        "    imcount = min(len(data), max_images) if max_images > 0 else len(data)\n",
        "    rows = int(np.ceil(imcount / 4))\n",
        "    fig, axs = plt.subplots(ncols=4, nrows=rows, figsize=(15, rows * 5), sharey=True, sharex=True)\n",
        "    axs = axs.flatten()\n",
        "    idxs = range(imcount)\n",
        "    if random:\n",
        "        idxs = np.random.choice(len(data), size=imcount)\n",
        "    for ax, i in enumerate(idxs):\n",
        "        item = data[i]\n",
        "        if hasattr(data, 'classes') and type(item) is tuple and len(item) == 2 and type(item[1]) is int:\n",
        "            item = item[0], data.classes[item[1]]\n",
        "        imshow(item, plt_ax=axs[ax])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEr2q4v8kYBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Class for working with a dataset.\"\"\"\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, '%sA' % mode) + '/*.*'))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, '%sB' % mode) + '/*.*'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n",
        "\n",
        "        if self.unaligned:\n",
        "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]))\n",
        "        else:\n",
        "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n",
        "\n",
        "        return {'A': item_A, 'B': item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_NLO_txc-D-",
        "colab_type": "text"
      },
      "source": [
        "# Architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdBFs3gMkYBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features)  ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block       \n",
        "        model = [   nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(input_nc, 64, 7),\n",
        "                    nn.InstanceNorm2d(64),\n",
        "                    nn.ReLU(inplace=True) ]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = 64\n",
        "        out_features = in_features*2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features*2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features//2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features//2\n",
        "\n",
        "        # Output layer\n",
        "        model += [  nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(64, output_nc, 7),\n",
        "                    nn.Tanh() ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # A bunch of convolutions one after another\n",
        "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(128), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(256), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
        "                    nn.InstanceNorm2d(512), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        # FCN classification layer\n",
        "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBYlklAkYBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return)\n",
        "\n",
        "class LambdaLR():\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)\n",
        "        \n",
        "def tensor2image(tensor):\n",
        "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
        "    if image.shape[0] == 1:\n",
        "        image = np.tile(image, (3,1,1))\n",
        "    return image.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Jb-jMVdEud",
        "colab_type": "text"
      },
      "source": [
        "# Initializing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amaZnTGOkYBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 0 # starting epoch\n",
        "n_epochs = 200 #200 # number of epochs of training\n",
        "batchSize = 6 # size of the batches\n",
        "dataroot = './white2black/' # root directory of the dataset\n",
        "lr = 0.0001 # initial learning rate\n",
        "decay_epoch = 100 # epoch to start linearly decaying the learning rate to 0\n",
        "size = 256 # size of the data crop (squared assumed)\n",
        "input_nc = 3 # number of channels of input data\n",
        "output_nc = 3 # number of channels of output data\n",
        "n_cpu = 2 # number of cpu threads to use during batch generation (I have only 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiwIyjDFkYBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfering Nets to GPU (or CPU).\n",
        "netG_A2B = Generator(input_nc, output_nc).to(device)\n",
        "netG_B2A = Generator(output_nc, input_nc).to(device)\n",
        "netD_A = Discriminator(input_nc).to(device)\n",
        "netD_B = Discriminator(output_nc).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XxPsrCkkYBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lossess\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "# Optimizers & LR schedulers\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                                lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "\n",
        "# Inputs & targets memory allocation\n",
        "input_A = torch.zeros((batchSize, input_nc, size, size), requires_grad=False).to(device)\n",
        "input_B = torch.zeros((batchSize, output_nc, size, size), requires_grad=False).to(device)\n",
        "target_real = torch.ones(batchSize, requires_grad=False).to(device)\n",
        "target_fake = torch.zeros(batchSize, requires_grad=False).to(device)\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# Dataset loader\n",
        "transforms_ = [ transforms.Resize(int(size*1.12), Image.BICUBIC), \n",
        "                transforms.RandomCrop(size), \n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "\n",
        "# Dataset cleaner. We get rid of the non RGB images.\n",
        "data = ImageDataset(dataroot, transforms_=transforms_, unaligned=True)\n",
        "\n",
        "mode_to_bpp = {'1':1, 'L':8, 'P':8, 'RGB':24, 'RGBA':32, 'CMYK':32, 'YCbCr':24, 'I':32, 'F':32}\n",
        "for d in data.files_A:\n",
        "    if mode_to_bpp[Image.open(d).mode] != 24:\n",
        "        os.remove(d)\n",
        "for d in data.files_B:\n",
        "    if mode_to_bpp[Image.open(d).mode] != 24:\n",
        "        os.remove(d)\n",
        "        \n",
        "# Initializing a dataloader.\n",
        "dataloader = torch.utils.data.DataLoader(data, \n",
        "                        batch_size=batchSize, shuffle=True, num_workers=min(0, n_cpu, batchSize))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58zzCiHrxjYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b0e4105-2a51-42be-ffed-a960db3bb06f"
      },
      "source": [
        "# Loading weights from the Google Disk.\n",
        "netG_A2B.load_state_dict(torch.load('gdrive/My Drive/netG_A2B_WB.pth'))\n",
        "netG_B2A.load_state_dict(torch.load('gdrive/My Drive/netG_B2A_WB.pth')) \n",
        "netD_A.load_state_dict(torch.load('gdrive/My Drive/netD_A_WB.pth'))\n",
        "netD_B.load_state_dict(torch.load('gdrive/My Drive/netD_B_WB.pth'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsStOqrbd4yr",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3j11XLWkYBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epoch, n_epochs):\n",
        "    for i in range(len(dataloader)):\n",
        "        # Here we except the FileNotFoundError and OSError.\n",
        "        # This part of the code doesn't look very aesthetically pleasing,\n",
        "        # but that's the price.\n",
        "        # The dataloader object does not support index iteration,\n",
        "        # so you have to take the first element from it and stop iteration.\n",
        "        # Thanks to the shuffle=True parameter,\n",
        "        # this element will not be repeated every time.\n",
        "        try:\n",
        "            for d in dataloader:\n",
        "                batch = d\n",
        "                break\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        except OSError:\n",
        "            continue\n",
        "        # Set model input\n",
        "        real_A = input_A.copy_(batch['A'])\n",
        "        real_B = input_B.copy_(batch['B'])\n",
        "        \n",
        "        if real_A.shape[1] != 3 or real_B.shape[1] != 3:\n",
        "            continue\n",
        "\n",
        "        ###### Generators A2B and B2A ######\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Identity loss\n",
        "        # G_A2B(B) should equal B if real B is fed\n",
        "        same_B = netG_A2B(real_B)\n",
        "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
        "        # G_B2A(A) should equal A if real A is fed\n",
        "        same_A = netG_B2A(real_A)\n",
        "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
        "\n",
        "        # GAN loss\n",
        "        fake_B = netG_A2B(real_A)\n",
        "        pred_fake = netD_B(fake_B)\n",
        "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        fake_A = netG_B2A(real_B)\n",
        "        pred_fake = netD_A(fake_A)\n",
        "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        # Cycle loss\n",
        "        recovered_A = netG_B2A(fake_B)\n",
        "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
        "\n",
        "        recovered_B = netG_A2B(fake_A)\n",
        "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
        "\n",
        "        # Total loss\n",
        "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "        loss_G.backward()\n",
        "        \n",
        "        optimizer_G.step()\n",
        "\n",
        "        ###### Discriminator A ######\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = netD_A(real_A)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "\n",
        "        # Fake loss\n",
        "        fake_A2 = fake_A_buffer.push_and_pop(fake_A)\n",
        "        pred_fake = netD_A(fake_A2.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_A.backward()\n",
        "\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        ###### Discriminator B ######\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = netD_B(real_B)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "        \n",
        "        # Fake loss\n",
        "        fake_B2 = fake_B_buffer.push_and_pop(fake_B)\n",
        "        pred_fake = netD_B(fake_B2.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_B.backward()\n",
        "\n",
        "        optimizer_D_B.step()\n",
        "        \n",
        "        if i % 10 == 0:\n",
        "            clear_output(wait=True)\n",
        "            print('{}/{} epoch. {}/{} batch'.format(epoch, n_epochs, i, len(dataloader)))\n",
        "            grid_show([real_A[0], fake_B[0].detach(), real_B[0], fake_A[0].detach()])\n",
        "            plt.show()\n",
        "\n",
        "    # Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "    \n",
        "    # Save the weights\n",
        "    torch.save(netG_A2B.state_dict(), f'gdrive/My Drive/netG_A2B_WB{str(epoch)}.pth')\n",
        "    torch.save(netG_B2A.state_dict(), f'gdrive/My Drive/netG_B2A_WB{str(epoch)}.pth')\n",
        "    torch.save(netD_A.state_dict(), f'gdrive/My Drive/netD_A_WB{str(epoch)}.pth')\n",
        "    torch.save(netD_B.state_dict(), f'gdrive/My Drive/netD_B_WB{str(epoch)}.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFrQaXicA53S",
        "colab_type": "text"
      },
      "source": [
        "# Results (Test)"
      ]
    }
  ]
}